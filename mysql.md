# mysql

## 一条sql的执行流程

![1](images/sqlzhixingliucheng.png)

步骤：

一：客户端层
id为1的name字段原来的值是zhuge。

①：mysql的客户端执行sql

 ```sql
update t set name = 'zhuge666' where id = 1   
 ```

二：mysql服务器层
②： 进入mysql服务器，由连接器验证账号密码等身份信息，验证通过去查mysql缓存，如果有，直接返回。没有进入分析器。
③：进入mysql的分析器，分析sql语句是否符合mysql规范。
④：进入sql优化器，mysql底层优化sql，比如调换索引列等。
⑤：进入执行器，执行sql。
        
三：innoDB引擎层
mysql服务层后边连接了很多引擎层，如MyIsam、innoDB等，这里只分析innoDB引擎。

⑥：加载磁盘上id为1的整页数据到 buff pool缓存池中，此时buff pool中的name值为zhuge，为什么加载整页，因为磁盘上存储数据都是整页整页存的。这里要注意：mysql加载数据是整页整页加载的！！
⑦：把buff pool中的 旧值 zhuge 写入undo日志版本链，方便事务提交失败后回滚，回滚时直接从undo日志版本链中取值即可。
⑧：在buff pool中把新的值 zhuge666 赋给 name，注意此时只有buff pool中的name属性做了更新，磁盘上的文件还是原来的旧值 zhuge。
⑨：执行器把更新的操作先写入内存中的Redo Log buffer（Redo日志缓冲区）
⑩：把Redo日志缓冲区分批次顺序写入inndb独有的redo磁盘日志文件中，此时准备提交事务
⑪：把更新操作写入binlog日志，内容与redo日志差不多，属于mysql服务层，所有引擎层都有这一步操作。此时还是准备提交事务中，还没提交 。
⑫：写一个commit标记到redo日志中去，该标记为了保证事务提交后，redo日志和binlog日志数据一致。此时才标志着提交事务完成
问题一：binlog为什么要给redo日志中写一个commit标记？

        binlog主要用于恢复数据，提交事务时，要给redo日志中写一个commit标记可以保证binlog日志中的数据与redo日志中的数据保持一致性

问题二：磁盘文件的数据什么时候更新？

        不确定，有一个后台io线程从Buffer pool缓存池中随机以页为单位写入磁盘。

问题三：如果事务提交后，数据库服务挂了，此时buff pool的数据还没来得及更新到磁盘上，怎么办？

        当再次重启服务器时，可以使用redo日志里的数据恢复buff pool中的数据，后台线程再把数据从buff pool中写入磁盘，这也是redo日志的最主要作用

问题四：为什么Mysql不能直接更新磁盘上的数据，而是设置这么一套复杂的机制来执行SQL？

①：内存操作，异步刷盘：如果每个请求都要来更新磁盘，数据库性能将特别差。利用buff poll缓存池在内存中操作数据，定时写入磁盘，大大提高了数据库性能。
②：redo日志顺序写入磁盘：redo日志虽然也使用磁盘存储，但相对与直接随机读写磁盘来说，redo日志是顺序写磁盘日志文件的。顺序写入的速度远高于随机写入，同时redo日志还能保证各种异常情况下的数据一致性。
        正是通过这套机制，才能让我们的MySQL数据库在较高配置的机器上每秒可以抗下几干的读写请求。
        

2. undo日志、redo日志、binlog日志的区别？
三种日志都写入磁盘！不过undo日志和redo日志是innoDB存储特有的，binlog日志是所有存储引擎都有的！

undo日志：主要用于mvcc机制的实现，还有事务回滚也可直接从undo日志中取到原始值
redo日志：主要用于防止mysql宕机时，buff pool中的数据还未来得及写入磁盘，导致数据丢失。使用redo日志可在mysql宕机后再启动时，把数据恢复到buff pool中。第二点就是等待binlog日志发送commit标记后才提交事务，保证与binlog日志文件数据一致！

binlog日志：主要用于数据库数据误删恢复，主从复制

>https://blog.51cto.com/u_15281317/2942322

## 事务

### 事务的隔离级别

1. 串行化

   多个事务只能一个一个执行，表现为串行化。可以解决幻读问题。

   如何才能实现串行化呢？它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

2. 可重复读    [幻读] 

   多个并发事务中，被某个事务A读取的行不可以被其他的事务B或C写（修改），但是可以往表中新增数据。有**幻读问题**，可通过间隙锁解决。

3. 读取提交内容     [不可重复读、幻读]

   多个并发事务中，被某个事务A读取的行是被其他事务B或C提交了的，但是可能前后两次读取的数据不一致，因为两次之间有其他事务提交了行数据。

4. 读取未提交内容   [脏读、不可重复读、幻读]

   随机读，事务A读取的数据，事务B或C可以随意修改，甚至未提交的数据也可以读取到，有**脏读问题**。

   

事务隔离级别都是表象，是数据库的规范，核心是怎么实现它，这里只研究mysql

##### mysql锁：

| 互斥性 | S    | X    |
| ------ | ---- | ---- |
| S      | 兼容 | 互斥 |
| X      | 互斥 | 互斥 |

##### 表锁：

​	在系统变量autocommit=0，innodb_table_locks = 1时，手动获取InnoDB存储引擎提供的表t的S锁或者X锁，可以这么写

1. 共享锁（S锁）

   ```sql
   lock tables t read
   ```

2. 排他锁（X锁）

   ```sql
   lock tables t write
   ```

   对表结构进行修改的时候，比如ALTER TABLE，DROP TABLE 的时候会加表X锁  

   可以手动加S表锁，那么Innodb加了S锁后,其他事务还可以获取S表锁，但是不能获取X锁。

#### 记录锁（行锁）

1. 共享锁

2. 排他锁

3. 间隙锁  记录锁   临键锁(间隙锁+记录锁)

4. 可以主动加锁

5. 举例

   | id   | name | age  |
   | ---- | ---- | ---- |
   | 1    | 张三 | 10   |
   | 2    | 李四 | 12   |
   | 8    | 王五 | 3    |

   

   1. update  table_name  set  name =  'job' where  id  = 1 for  update   这里就给id=1的记录加了记录锁

   2. update  table_name  set  name =  'job' where  id  = 5 for  update   这就加上了间隙锁  锁住了  (2 , 8)

      引申：间隙锁是锁住两个值之前的间隙，要锁住最后一条记录后面的间隙怎么办，可以使用mysql的分页结构，每一页上都有supernum这个记录，代表∞

   3. update  table_name  set  name =  'job' where  id  >= 2 for  update   这就加上了临键锁，锁住了  [2 , ∞)

### Innodb如何实现事务隔离?什么是MVCC!!!

innodb通过mvcc实现  **读已提交** 和 **可重复度**

1. mvcc时什么：  多版本并发控制技术，其基本思想是为每次事务生成一个新版本的数据，在读取时选择不同版本的数据即可以实现对事务完整结果的读取（在其他的并发应用中也有）

2. 作用：提高并发的读写性能，因为读可以不用加锁了

   **增删改的时候会生成事务id**  

   开启标志：任何一条DML语句(insert、update、delete)执行，事务开启。set autocommit=0 控制事务自动提交而已。

   - 每一条record里面都包含三个隐藏字段  row_id, tx_id, roll_pointer 

     - row_id 自增的行id，如果没有指定主键，innodb会默认以此字段为主键 
     - tx_id 记录最后被哪个事务修改，这里存的就是哪个事务id
     - roll_pointer 回滚指针，每次对某条聚集索引记录进行改动时，都会把旧的版本写入undo日志中。这个隐藏列就相当于一个指针，通过他找到该记录修改前的信息，其实也是该条数据最新的undo log记录

   - undo log中的记录，和数据库中的记录格式一样，回滚指针指向前一条undo log记录(如果有的话)

     >undo log番外篇  目的是为了事务回滚用的，那么我们不需要保存太多数据，策略不秦楚，但是可以设置文件滚动使用

   - ![img](images/undolog.png)**mvcc开始工作：**

   - 当事务中有查询语句时，生成一个**readView**,以下时它的主要组成部分

     - **「m_ids」**：在生成ReadView时，当前系统中**活跃的事务id列表**
     - **「min_trx_id」**：在生成ReadView时，当前系统中活跃的最小的事务id，也就是m_ids中的最小值
     - **「max_trx_id」**：在生成ReadView时，系统应该分配给下一个事务的事务id值（因为事务id是自增的）
     - **「creator_trx_id」**：生成该ReadView的事务的事务id，如果查询事务中没有cud操作，那么当前事务id为0

   - 举例说明

   - **读已提交**:**每次读取数据前都生成一个ReadView**

   - ![](images/modb_20210928_95d04720-2024-11ec-9f93-00163e068ecd.png)

     下面是3个事务执行的过程，一行代表一个时间点

     ![img](images/tx_do.png)

     **「先分析一下5这个时间点select的执行过程」**

     1. 系统中有两个事务id分别为100，200的事务正在执行
     2. 执行select语句时生成一个ReadView，mids=[100,200]，min_trx_id=100，max_trx_id=201，creator_trx_id=0（select这个事务没有执行更改操作，事务id默认为0）
     3. 最新版本的name列为西施，该版本trx_id值为100，在mids列表中，不符合可见性要求，根据roll_pointer跳到下一个版本
     4. 下一个版本的name列王昭君，该版本的trx_id值为100，也在mids列表内，因此也不符合要求，继续跳到下一个版本
     5. 下一个版本的name列为貂蝉，该版本的trx_id值为10，小于min_trx_id，因此最后返回的name值为貂蝉
     
     ![](images/modb_20210928_95d04720-2024-11ec-9f93-00163e068ecd.png)

**Repeatable Read（可重复读），在第一次读取数据时生成一个ReadView**

![img](images/modb_20210928_96508ffc-2024-11ec-9f93-00163e068ecd.png)

### 串行化如何实现

当我们设置innodb隔离级别为串行化的时候，引擎会使用间隙锁达到串行化的效果，以解决幻读。

当然可能也是表锁，当我们的查询范围没有走索引（全表扫描）的时候。加共享锁（S锁）即可。

间隙锁是给不存在的数据记录的范围加锁：

对于辅助索引，若值允许重复，在串行隔离级别中如果进行等值查询，InnoDB会给数据加上行锁和间隙锁（防止别的事务插入索引值重复的数据，造成幻读）
对于主键索引，或者唯一键索引，值不允许重复，那只需要加行锁就够了（对于唯一键索引，不可能发生插入索引值重复的数据）

### mysql innodb文件体系

![1](images/mysql_file.png)

https://blog.csdn.net/Edwin_Hu/article/details/124698400

### 优化锁方面的意见？

* 使用较低的隔离级别
* 设计索引，尽量使用索引去访问数据，加锁更加精确，从而减少锁冲突
* 选择合理的事务大小，给记录显示加锁时，最好一次性请求足够级别的锁。列如，修改数据的话，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，这样会导致死锁
* 不同的程序访问一组表的时候，应尽量约定一个相同的顺序访问各表，对于一个表而言，尽可能的固定顺序的获取表中的行。这样大大的减少死锁的机会。
* 尽量使用相等条件访问数据，这样可以避免间隙锁对并发插入的影响
* 不要申请超过实际需要的锁级别
* 数据查询的时候不是必要，不要使用加锁。MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能：MVCC只在committed read（读提交）和 repeatable read （可重复读）两种隔离级别
* 对于特定的事务，可以使用表锁来提高处理速度减少死锁的可能。

### 分库分表

#### 1. 为什么要分库分表？

**分表**

比如你单表都几千万数据了，你确定你能扛住么？绝对不行，单表数据量太大，会极大影响你的 sql执行的性能，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。

分表就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。

**分库**

分库就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。

这就是所谓的分库分表。

#### 分库分表中间件 sharding-jdbc

当当开源的，属于 client 层方案。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且目前推出到了 2.0 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也**可以选择的方案**。

## 4. MySQL主从复制流程和原理？

基本原理流程，是3个线程以及之间的关联

主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中；

从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中；

从：sql执行线程——执行relay log中的语句；

**复制过程如下**：

![img](images/mysql_m_s.png)

Binary log：主数据库的二进制日志

Relay log：从服务器的中继日志

第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。

第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。

第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。

## 5. MySQL主从同步延时问题如何解决？

MySQL 实际上在有两个同步机制，一个是半同步复制，用来 解决主库数据丢失问题；一个是并行复制，用来 解决主从同步延时问题。

- 半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。
- 并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

### 主从延迟的解决方案

解决主从延迟主要有以下方案：

- 配合 semi-sync 半同步复制；
- 一主多从，分摊从库压力；
- 强制走主库方案（强一致性）；
- sleep 方案：主库更新后，读从库之前先 sleep 一下；
- 判断主备无延迟方案（例如判断 seconds_behind_master 参数是否已经等于 0、对比位点）；
  并行复制 — 解决从库复制延迟的问题；
- 这里主要介绍我在项目中使用的几种方案，分别是半同步复制、实时性操作强制走主库、并行复制。

##### semi-sync 半同步复制

MySQL 有三种同步模式，分别是：

「异步复制」：MySQL 默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给客户端，并不关心从库是否已经接收并处理。这样就会有一个问题，一旦主库宕机，此时主库上已经提交的事务可能因为网络原因并没有传到从库上，如果此时执行故障转移，强行将从提升为主，可能导致新主上的数据不完整。

「全同步复制」：指当主库执行完一个事务，并且所有的从库都执行了该事务，主库才提交事务并返回结果给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。

「半同步复制」：是介于全同步复制与全异步复制之间的一种，主库只需要等待至少一个从库接收到并写到 Relay Log 文件即可，主库不需要等待所有从库给主库返回 ACK。主库收到这个 ACK 以后，才能给客户端返回 “事务完成” 的确认。

MySQL 默认的复制是异步的，所以主库和从库的数据会有一定的延迟，更重要的是异步复制可能会引起数据的丢失。但是全同步复制又会使得完成一个事务的时间被拉长，带来性能的降低。因此我把目光转向半同步复制。从 MySQL 5.5 开始，MySQL 以插件的形式支持 semi-sync 半同步复制。

相对于异步复制，半同步复制提高了数据的安全性，减少了主从延迟，当然它也还是有一定程度的延迟，这个延迟最少是一个 TCP/IP 往返的时间。所以，半同步复制最好在低延时的网络中使用。

需要注意的是：

主库和从库都要启用半同步复制才会进行半同步复制功能，否则主库会还原为默认的异步复制。
如果在等待过程中，等待时间已经超过了配置的超时时间，没有收到任何一个从库的 ACK，那么此时主库会自动转换为异步复制。当至少一个半同步从节点赶上来时，主库便会自动转换为半同步复制。
半同步复制的潜在问题
在传统的半同步复制中（MySQL 5.5 引入），主库写数据到 binlog，并且执行 commit 提交事务后，会一直等待一个从库的 ACK，即从库写入 Relay Log 后，并将数据落盘，再返回给主库 ACK，主库收到这个 ACK 以后，才能给客户端返回 “事务完成” 的确认。

![在这里插入图片描述](images/d77fcd65e53a466aaab8ba097f661d89.jpeg)

这样会出现一个问题，就是实际上主库已经将该事务 commit 到了存储引擎层，应用已经可以看到数据发生了变化，只是在等待返回而已。如果此时主库宕机，可能从库还没写入 Relay Log，就会发生主从库数据不一致。

为了解决上述问题，MySQL 5.7 引入了增强半同步复制。针对上面这个图，“Waiting Slave dump” 被调整到了 “Storage Commit” 之前，即主库写数据到 binlog 后，就开始等待从库的应答 ACK，直到至少一个从库写入 Relay Log 后，并将数据落盘，然后返回给主库 ACK，通知主库可以执行 commit 操作，然后主库再将事务提交到事务引擎层，应用此时才可以看到数据发生了变化。

![img](images/3185eab52ac145659f1a2218213bd7b6.png)

当然之前的半同步方案同样支持，MySQL 5.7.2 引入了一个新的参数 rpl_semi_sync_master_wait_point 进行控制。这个参数有两种取值：

AFTER_SYNC：这个是新的半同步方案，Waiting Slave dump 在 Storage Commit 之前。
AFTER_COMMIT：这个是老的半同步方案。
在 MySQL 5.5 - 5.6 使用 after_commit 的模式下，客户端事务在存储引擎层提交后，在主库等待从库确认的过程中，主库宕机了。此时，结果虽然没有返回给当前客户端，但事务已经提交了，其他客户端会读取到该已提交的事务。如果从库没有接收到该事务或者未写入 relay log，同时主库宕机了，之后切换到备库，那么之前读到的事务就不见了，出现了幻读，也就是数据丢失了。

MySQL 5.7 默认值则是 after_sync，主库将每个事务写入 binlog，传给从库并刷新到磁盘 (relay log)。主库等到从库返回 ack 之后，再提交事务并且返回 commit OK 结果给客户端。 即使主库 crash，所有在主库上已经提交的事务都能保证已经同步到从库的 relay log 中，解决了 after_commit 模式带来的幻读和数据丢失问题，故障切换时数据一致性将得到提升。因为从库没有写入成功的话主库也不会提交事务。并且在 commit 之前等待从库 ACK，还可以堆积事务，有利于 group commit 组提交，有利于提升性能。

但这样也会有个问题，假设主库在存储引擎提交之前挂了，那么很明显这个事务是不成功的，但由于对应的 Binlog 已经做了 Sync 操作，从库已经收到了这些 Binlog，并且执行成功，相当于在从库上多了数据（从库上有该数据而主库没有），也算是有问题的，但多了数据一般不算严重的问题。它能保证的是不丢数据，多了数据总比丢数据要好。

一主多从
如果<u>从库承担了大量查询请求</u>，那么从库上的查询操作将耗费大量的 CPU 资源，从而影响了同步速度，造成主从延迟。那么我们可以多接几个从库，让这些从库来共同分担读的压力。

简而言之，就是加机器，方法简单粗暴，但也会带来一定成本。

##### 强制走主库方案

如果某些操作对数据的实时性要求比较苛刻，需要反映实时最新的数据，比如说涉及金钱的金融类系统、在线实时系统、又或者是写入之后马上又读的业务，这时我们就得放弃读写分离，让此类的读请求也走主库，这就不存延迟问题了。

当然这也失去了读写分离带给我们的性能提升，需要适当取舍。

##### 并行复制

一般 MySQL 主从复制有三个线程参与，都是单线程：Binlog Dump 线程、IO 线程、SQL 线程。复制出现延迟一般出在两个地方：

SQL 线程忙不过来（主要原因）；
网络抖动导致 IO 线程复制延迟（次要原因）。
日志在备库上的执行，就是备库上 SQL 线程执行中继日志（relay log）更新数据的逻辑。

在 MySQL 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。从 MySQL 5.6 开始有了多个 SQL 线程的概念，可以并发还原数据，即并行复制技术。这可以很好的解决 MySQL 主从延迟问题。

从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。其实说到底，所有的多线程复制机制，都是要把只有一个线程的 sql_thread，拆成多个线程，也就是都符合下面的这个多线程模型：
![在这里插入图片描述](images/b026ac1be3494defb3f5d84a92b71df5.png)

coordinator 就是原来的 sql_thread，不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 worker 线程的个数，就是由参数 slave_parallel_workers 决定的。

由于 worker 线程是并发运行的，为了保证事务的隔离性以及不会出现更新覆盖问题，coordinator 在分发的时候，需要满足以下这两个基本要求：

更新同一行的两个事务，必须被分发到同一个 worker 中（避免更新覆盖）。
同一个事务不能被拆开，必须放到同一个 worker 中（保证事务隔离性）。
各个版本的多线程复制，都遵循了这两条基本原则。

## 4. TCC(分布式事务最优解)

TCC是柔性事务，而上面介绍的都是刚性事务。有时候，一个技术问题，可以通过业务建模来实现。

2PC和3PC在概念上看起来虽然简单，但放在分布式环境中，考虑各种超时和宕机问题，如果考虑的周全，那可真是要了老命。

2PC的框架还是比较多的，但3PC全网找了个遍，发现有名的实现几乎没有。

不要伤心，我们有更容易理解，更加直观的分布式事务。那就是TCC，2007年的老古董。

TCC就是大名鼎鼎的补偿事务，是互联网环境最常用的分布式事务。它的核心思想是：为每一个操作，都准备一个确认动作和相应的补偿动作，一共3个方法。

与其靠数据库，不如靠自己的代码！2PC，3PC，都和数据库绑的死死的，TCC才是码农的最爱（意思就是说，你要多写代码）。

![image-20210914162640227.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4a2b62f5c33948f08a8ac757e8816bfc~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp?)

如图，TCC同样分为三个阶段，但非常的粗暴！

- try 尝试阶段 尝试锁定资源
- confirm 确认阶段 尝试将锁定的资源进行提交
- cancel 取消阶段 其中某个环节执行失败，将发起事务取消动作

看起来这三个阶段，是2阶段提交的一种？完全不是。但它们的过程可以比较一下。

```bash
TCC					2PC
Try					业务逻辑
Confirm 			commit-request/voting + commit
Cancel  			rollback
```

从上面可以看出来，2PC是一种对事务过程的划分，而TCC是对正常情况的提交和异常情况的补偿。相对于传统的代码，try和confirm两者加起来，才是真正的业务逻辑。

TCC是非常容易理解的，但它有一个大的前提，就是这三个动作必须都是幂等的，对业务有一定的要求。拿资金转账来说，try就是冻结金额；confirm就是完成扣减；cancel就是解冻，只要对应的订单号是一直的，多次执行也不会有任何问题。

由于TCC事务的发起方，直接在业务节点即可完成，和TCC的代码在同一个地方。所以，TCC并不需要一个额外的协调者和事务处理器，它存放在本地表或者资源中即可。

是的，它也要记录一些信息，哪怕是HashMap里，否则它根据啥回滚呢？



## 3. 超大分页怎么处理?

数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于`select * from table where age > 20 limit 1000000`,10 这种查询其实也是有可以优化的余地的. 这条语句需要 load1000000 数据然后基本上全部丢弃,只取 10 条当然比较慢. 当时我们可以修改为`select * from table where id in (select id from table where age > 20 limit 1000000,10)`.这样虽然也 load 了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快。

解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可.

在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种.

> 【推荐】利用延迟关联或者子查询优化超多分页场景。 
>
> 说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 
>
> 正例：先快速定位需要获取的id段，然后再关联： 
>
> SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id=b.id

## 6. 如何优化关联查询

- 确定ON或者USING子句中是否有索引。
- 确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。